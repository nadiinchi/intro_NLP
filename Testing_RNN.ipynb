{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование  рекуррентной нейронной сети для генерации текстов\n",
    "\n",
    "В этом ноутбуке мы рассмотрим рекуррентную нейросеть небольшого размера, обученную на первом томе романа \"Война и мир\" Л. Н. Толстого. Такая нейронная сеть умеет генерировать продолжения фраз на русском языке. \n",
    "\n",
    "В задании Вы:\n",
    "* сгенерируете свои предсказания с помощью нейронной сети\n",
    "* визуализируете векторные представления слов с помощью метода tSNE\n",
    "* поищите близкие слова с помощью векторных представлений слов\n",
    "* попробуете вычислять метрику BLEU, оценивающую похожесть двух текстовых последовательностей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = Namespace(\n",
    "    seq_size=32, # максимальная длина текста (в словах)\n",
    "    embedding_size=64, # число элементов в векторных представлениях слов\n",
    "    lstm_size=64, # число нейронов в рекуррентном слое\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сборка нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModule(nn.Module):\n",
    "    def __init__(self, n_vocab, seq_size, embedding_size, lstm_size):\n",
    "        super(RNNModule, self).__init__()\n",
    "        self.seq_size = seq_size\n",
    "        self.lstm_size = lstm_size\n",
    "        # слой векторных представлений (эмбеддингов)\n",
    "        self.embedding = nn.Embedding(n_vocab, embedding_size)\n",
    "        # рекуррентный слой\n",
    "        self.lstm = nn.LSTM(embedding_size,\n",
    "                            lstm_size,\n",
    "                            batch_first=True)\n",
    "        # полносвязный слой для предсказания следующего слова\n",
    "        self.dense = nn.Linear(lstm_size, n_vocab)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        # x: (16, 32): 16 объектов, 32 слова в каждом\n",
    "        embed = self.embedding(x) # (16, 32, 64): 64 - размер векторного представления\n",
    "        output, state = self.lstm(embed, prev_state) # (16, 32, 64)\n",
    "        logits = self.dense(output) # (16, 32, 22782), 22782 - число слов в словаре\n",
    "\n",
    "        return logits, state\n",
    "\n",
    "    def zero_state(self, batch_size):\n",
    "        return (torch.zeros(1, batch_size, self.lstm_size),\n",
    "                torch.zeros(1, batch_size, self.lstm_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cоздаем конкретный экземпляр нейросети (пока с бессмысленными случайно инициализированными весами):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = RNNModule(22782, flags.seq_size,\n",
    "                flags.embedding_size, flags.lstm_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных и обученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = torch.load(\"/home/sber50/notebooks/net.dict\")\n",
    "net.load_state_dict(save[\"net\"])\n",
    "n_vocab = save[\"n_vocab\"]\n",
    "vocab_to_int = save[\"vocab_to_int\"]\n",
    "int_to_vocab = save[\"int_to_vocab\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22782"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на 20 самых частых слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",\n",
      ".\n",
      "и\n",
      "—\n",
      "в\n",
      "не\n",
      "на\n",
      "что\n",
      "он\n",
      "с\n",
      "как\n",
      "!\n",
      "к\n",
      "его\n",
      "?\n",
      "сказал\n",
      "я\n",
      "было\n",
      "это\n",
      ";\n"
     ]
    }
   ],
   "source": [
    "for idx in range(20):\n",
    "    print(int_to_vocab[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем номер слова \"Наташа\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_to_int[\"Наташа\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция для выполнения предсказания\n",
    "\n",
    "Функция выполняет следующие шаги:\n",
    "* предобработка заданной последовательности (разделение на слова по пробелам)\n",
    "* обработка последовательности с помощью нейросети\n",
    "* предсказание следующего слова заданное количество раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(net, n_vocab, vocab_to_int, int_to_vocab,\n",
    "             words=\"Зачем мне\", top_k=5, length=100):\n",
    "    words = words.split() # разделение текста на слова по пробелам\n",
    "    \n",
    "    net.eval()\n",
    "\n",
    "    # обработка данных слов\n",
    "    state_h, state_c = net.zero_state(1)\n",
    "    for w in words:\n",
    "        ix = torch.tensor([[vocab_to_int[w]]])\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "\n",
    "    # предсказание первого следующего слова (случайный выбор из top_k слов)\n",
    "    _, top_ix = torch.topk(output[0], k=top_k)\n",
    "    choices = top_ix.tolist()\n",
    "    choice = np.random.choice(choices[0])\n",
    "\n",
    "    words.append(int_to_vocab[choice])\n",
    "\n",
    "    # повторение процедуры генерации length раз\n",
    "    for _ in range(length):\n",
    "        ix = torch.tensor([[choice]])\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "\n",
    "        _, top_ix = torch.topk(output[0], k=top_k)\n",
    "        choices = top_ix.tolist()\n",
    "        choice = np.random.choice(choices[0])\n",
    "        words.append(int_to_vocab[choice])\n",
    "\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выполняем предсказания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция predict принимает на вход следующие аргументы:\n",
    "* net: обученная нейросеть - см. раздел Загрузка данных и обученной модели\n",
    "* n_vocab: число слов в словаре - см. раздел Загрузка данных и обученной модели\n",
    "* vocab_to_int: словарь, возвращающий номер слова - см. раздел Загрузка данных и обученной модели\n",
    "* int_to_vocab: словарь, возвращающий слова по их номеру - см. раздел Загрузка данных и обученной модели\n",
    "* (!) my_input: строка, которую нужно продолжить\n",
    "* (!) top_k: из скольки слов с наибольшими предсказанными вероятностями выбирать следующее слово \n",
    "* (!) length: сколько слов генерировать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример генерации продолжения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Завтра поедем выбирать новую шубу , — сказала старая графиня , проходя через залу и улыбнулась'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_input = \"Завтра поедем выбирать новую шубу\"\n",
    "predict(net, n_vocab,\n",
    "                    vocab_to_int, int_to_vocab, my_input, top_k=1,\\\n",
    "       length=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание.__ Сгенерируйте продолжения для нескольких фраз, которые Вы придумаете. \n",
    "\n",
    "Если в Вашем предложении будут слова, которых не было в обучающих данных (в первом томе), выдастся ошибка. К сожалению, в этом случае придеся изменить предложение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание.__ Попробуйте варьировать параметры:\n",
    "* Попробуйте генерировать длинные продолжения: length=100. Верно ли, что в начале продолжения текст более осмысленный (хотя бы насколько-нибудь), чем в конце?\n",
    "* Попробуйте менять параметр top_k (из скольки наиболее вероятных следующих слов делать случайный выбор). Попробуйте k=1, k=3, k=20. Как влияет k на качество генерируемых продолжений?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация векторных представлений\n",
    "\n",
    "При обучении нейросети для каждого слова мы выучили векторное представление -- набор чисел, характеризующих его смысл. Этот набор чисел понятен только нейросети, мы его интерпретировать не можем. Но мы можем визуализировать векторные представления и попытаться найти в них какую-то структуру.\n",
    "\n",
    "Для начала извлечем таблицу векторных представлений из модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = net.embedding.weight.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22782, 64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs.shape # число слов, размер векторного представления"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример векторного представления:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.48384216,  0.3189694 ,  0.1700915 , -0.11458367, -0.10301524,\n",
       "       -1.1690301 ,  0.38778594,  0.5920238 ,  0.130598  ,  0.23635785,\n",
       "       -0.9997578 , -0.71189773, -0.3779874 , -0.711161  , -1.3358569 ,\n",
       "       -0.11525764,  0.241066  ,  0.1798417 ,  0.3323485 ,  0.57619524,\n",
       "       -0.57826173, -0.19859928,  0.24085268,  1.3594143 ,  0.4270676 ,\n",
       "        0.18791378,  0.3758226 ,  1.7573667 , -0.37461475,  0.90953875,\n",
       "        0.88424164, -0.16349766, -0.27682295, -0.7802633 , -0.6342541 ,\n",
       "        0.94474924,  0.6307871 , -0.18897489, -0.43013066, -2.1848588 ,\n",
       "       -0.98522854,  0.62291276, -2.720233  , -0.20365648, -0.3813623 ,\n",
       "       -0.7290697 ,  0.27388793,  0.6884718 , -0.03741877, -0.4365542 ,\n",
       "        0.8986192 , -0.58165354,  0.68537104, -0.26316145, -0.64776695,\n",
       "        0.49379987, -0.06059999, -0.04448707,  0.72009695,  0.8129411 ,\n",
       "        1.5799985 , -0.49638534, -1.7179551 , -0.10294399], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем визуализировать векторные представления с помощью метода tSNE: он находит для каждого слова точку на плоскости так, чтобы сохранить информацию о расстояниях между представлениями. \n",
    "\n",
    "Код для применения метода tSNE выглядит так:\n",
    "   \n",
    "tsne = TSNE()\n",
    "\n",
    "res = tsne.fit_transform(таблица векторных представлений)\n",
    "\n",
    "Вам нужно подставить в код выше первые 300 строк нашей таблицы векторных представлений. Чтобы выделить первые 300 строк, припишите к переменной [:300].\n",
    " \n",
    "__Задание.__ Примените метод tSNE к таблице векторных представлений слов (первые 300 слов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате для каждого из 300 слов мы знаем 2 координаты на плоскости, где расположить это слово:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним визуализацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = res[:, 0]\n",
    "y = res[:, 1]\n",
    "labels = [int_to_vocab[i] for i in range(len(x))]\n",
    "plt.figure(figsize=(16, 16)) \n",
    "for i in range(len(x)):\n",
    "    if x[i] > -200 and x[i] < 200 and y[i] > -200 and y[i] < 200:\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание.__ Рассмотрите визуализацию: найдите группы похожих слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поиск похожих слов\n",
    "\n",
    "Попробуем использовать наши векторные представления для поиска похожих слов. Код, данный ниже, находит для слова my_word топ-3 близких к нему слова.  Будем искать только среди первой тысячи слов, потому что для них выучились наиболее стабильные векторные представления.\n",
    "\n",
    "Вам нужно дописать начало этой функции: \n",
    "* idx: извлечь номер слова из словаря (используйте переменную vocab_to_int, созданную в разделе Загрузка данных и обученной модели)\n",
    "* my_emb: извлечь векторное представление по номеру (используйте переменную embs, созданную в разделе Визуализация векторных представлений)\n",
    "\n",
    "Для извлечения элемента используйте квадратные скобки.\n",
    "\n",
    "__Задание.__ Допишите функию find_words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_words(my_word):\n",
    "    ####### Ваш код здесь\n",
    "    idx = \n",
    "    my_emb =\n",
    "    ########\n",
    "    # вычисление расстояний до других слов\n",
    "    dists = pairwise_distances(embs[:1000], my_emb[None, :], \\\n",
    "                               metric=\"cosine\")\n",
    "    # поиск трех наиболее похожих\n",
    "    idxs2 = np.argsort(dists.ravel())[:3]\n",
    "    # печать результата\n",
    "    for idx2 in idxs2:\n",
    "        print(int_to_vocab[idx2], dists[idx2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем функцию: найдем слова, близкие к слову \"она\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "она [0.]\n",
      "Она [0.51782924]\n",
      "Княжна [0.6152046]\n"
     ]
    }
   ],
   "source": [
    "find_words(\"она\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание.__ Найдите слова, близкие к словам \"он\", \"офицер\", \"Ростова\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вычисление метрики BLEU\n",
    "\n",
    "Метрика BLEU измеряет, насколько похожи текстовые последовательности. Обычно ее используют в задаче перевода, когда смысл предложения, которое нужно предсказать, определен (совпадает со смыслом предложения на другом языке), но перевод можно сформулировать по-разному. Исследования показывают, что метрика BLEU неплохо коррелирует с экспертной оценкой переводов.\n",
    "\n",
    "Напишем простую функцию для вычисления метрики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def get_bleu(true, predicted):\n",
    "    reference = true.split()\n",
    "    hypothesis = predicted.split()\n",
    "    BLEUscore = nltk.translate.bleu_score.sentence_bleu([reference], hypothesis, \\\n",
    "                                                        weights = (0.5, 0.5))\n",
    "    return BLEUscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5163977794943222"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = \"Девушка держит чашку кофе\"\n",
    "predicted = \"Девушка держит в руке чашку кофе\"\n",
    "get_bleu(true, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание.__ Вычислите BLEU, когда предсказанное предложение в точности совпадает с правильным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание.__ Вычислите BLEU для своей модификации предложения про кофе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы можете также попробовать вычислять BLEU для своих пар предложений. \n",
    "\n",
    "Кроме того, можно попробовать найти строчку из [второго тома \"Войны и мира\"](http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0050.shtml), сделать для него предсказание с помощью нейронной сети и вычислить BLEU относительно настоящего продолжения из романа. \n",
    "\n",
    "Правда, скорее всего, Вы получите значение BLEU около нуля, потому что, вообще говоря, нейросеть не знает, о чем именно написано дальше в предложении, поэтому сгенерировать точное по смысле продолжение она гипотетически не может."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если Вы все сделали, предлагаем также попробовать демонстрации, доступные в онлайн-сервисах:\n",
    "* [Порфирьевич](https://porfirevich.ru/): решает ту же задачу, которую решали мы, однако нейросеть в сервисе обучена на большем объеме данных и имеет больше параметров, так что генерирует более осмысленные продолжения.\n",
    "* [Генерация подписей к изображениям](https://milhidaka.github.io/chainer-image-caption/): загрузите изображение (Choode file) и нажмите кнопку Generate caption. Для перевода результатов можно воспользоваться [Google-переводчиком](https://translate.google.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_pytorch",
   "language": "python",
   "name": "conda-env-py37_pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
